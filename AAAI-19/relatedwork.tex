% !TEX root = multitaskDPP.tex

\section{Related Work}
The topics of DPPs, basket completion, and diversity have significant attention
in the past several years.

In addition to the previously discussed work, DPPs have been used for natural
language processing in order to discover diverse threads of
documents~\cite{Gillenwater:2012:DDS:2390948.2391026}, and to enhance diversity
in recommender
systems~\cite{Foulds2013DiversePW,DBLP:journals/corr/abs-1709-05135}. Unlike our
application where we learn the kernels, in these applications the kernel is
provided using previously obtained latent factors, for instance using tf-idf for
~\cite{Gillenwater:2012:DDS:2390948.2391026}. These latent factors are scaled by
a relevance score learned in a more conventional fashion. For example, these
relevance scores may represent the predicted rating of a particular user, or the
similarity between the text in a document and the user query. Ultimately, these
applications involve sampling from the DPP specified by this kernel, where the
kernel parameters trade off between relevance and diversity. However, sampling
from such a DPP efficiently is difficult, and this has lead to work on different
sampling techniques.  Ref.~\cite{DBLP:journals/corr/HanKPS17,NIPS2014_5564,DBLP:conf/icml/GautierBV17}
relies on MCMC sampling, while~\cite{DBLP:journals/corr/abs-1709-05135}
proposes a greedy solution based on Cholesky decomposition. 

Several algorithms have been proposed for learning the DPP kernel matrix.
Ref.~\cite{NIPS2014_5564} uses an expectation-maximization (EM) algorithm to
learn a non-parametric form of the DPP kernel matrix.
Ref.~\cite{DBLP:journals/corr/MarietS15} proposed a fixed-point algorithm called
Picard iteration, which proved to be much faster than EM, but still slower
than~\cite{DBLP:conf/aaai/GartrellPK17}. Bayesian learning methods have also
been proposed to learn the DPP
kernel~\cite{DBLP:conf/recsys/GartrellPK16,DBLP:conf/icml/AffandiFAT14}.

Improving diversity in recommender systems has also been studied without the use
of DPPs, including, among other work,
in~\cite{Christoffel:2015:BWA:2792838.2800180,PuthiyaParambath:2016:CAR:2959100.2959149,Teo:2016:APD:2959100.2959171,Vargas:2014:ISD:2645710.2645744,Paudel:2017:FFT:3109859.3109916}.
For instance,~\cite{Christoffel:2015:BWA:2792838.2800180} relies on random walk
technics to enhance diversity.
In~\cite{PuthiyaParambath:2016:CAR:2959100.2959149}, the authors propose trading
off between the relevance of the recommendation and diversity by introducing a
coverage function to force the algorithm to produce recommendations that cover
different centers of the interests of each user.
Ref.~\cite{Paudel:2017:FFT:3109859.3109916} proposes extensions of logistic
matrix factorization for two-class collaborative filtering. One of the methods
presented in this paper learns two sets of latent item factors, one for each
class, that represent positive and negative feedback, which prove the
effectiveness of this approach in producing recommendations that better cover
the catalog while maintaining accurate recommendations. Finally, the authors
of~\cite{Vargas:2014:ISD:2645710.2645744} propose transforming the problem of
recommending items to users into recommending users to items. They introduce a
modification of nearest-neighbor methods, and a probabilistic model that allows
isolation of the popularity bias and favors less popular items. 

Regarding basket completion, associative classifiers have long been the
state-of-the-art~\cite{Agrawal:1993:MAR:170036.170072,Hipp:2000:AAR:360402.360421,Liu:1998:ICA:3000292.3000305}, despite requiring
very heaving computational load for training, and manual tuning for key
parameter choices such as lift and confidence thresholds. Later work focuses on
the task of purchase prediction by adapting collaborative filtering methods.
Ref.~\cite{Mild2003} proposes a solution based on nearest-neighbor models,
while~\cite{Lee:2005:CCF:1707421.1707525} relies on binary logistic regression
to predict if a user will purchase a given item. More recently,
DPPs~\cite{DBLP:conf/aaai/GartrellPK17,DBLP:conf/recsys/GartrellPK16} may now be
considered among the class of models belonging to the new state-of-the-art for
basket completion, in light of their effectiveness both in terms of accuracy and
training speed. Finally, classic collaborative filtering models tailored for
positive and unlabelled
data~\cite{Paquet:2013:OCF:2488388.2488475,Hu:2008:CFI:1510528.1511352,DBLP:journals/corr/GopalanHB13}
may be effectively used for basket completion.

